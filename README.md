# Matemática esencial para Machine Learning en R

Vista la pagina del apunte del tema:

https://zpio.github.io/datascience/posts/Matematicas_Machine_Learning_R.html

Vista la pagina con mas apuntes:

https://zpio.github.io/datascience/

## Contenido:

- 1 Escalares, Vectores, y Matrices
  - 1.1 Definiendo un vector con c(), :, seq() y rep()
  - 1.2 Definiendo una matriz con matrix(), rbind()y cbind()
  - 1.3 Gráficas de vectores en 2-D y 3-D
- 2 Operaciones con Vectores
  - 2.1 Gráfica de vectores en 2D y 3D
  - 2.2 Multiplicación de un vector con un escalar
  - 2.3 Suma de vectores
  - 2.4 Resta de vectores
  - 2.5 Multiplicación y suma de vectores
  - 2.6 Gráfica de la suma de vectores
- 3 Operaciones con Matrices: Suma, Resta y Multiplicación
  - 3.1 Multiplicación de una matriz con un escalar
  - 3.2 Suma y Resta de matrices
  - 3.3 Multiplicación de matrices: Matricial y Elemento a Elemento
- 4 Operaciones con matrices: Matrices transpuestas, inversas e identidad
  - 4.1 Matriz Transpuesta - funcion t()
  - 4.2 Matriz inversa - funcion solve()
  - 4.3 Matriz identidad - funcion diag()
- 5 Introducción a Regresión Lineal
  - 5.1 Ejemplo Determinístico
  - 5.2 Ejemplo Estocástico
  - 5.3 Error del Modelo
- 6 Representación Matricial de la Regresión Lineal
  - 6.1 Traducir los componentes de regresión lineal a matrices
  - 6.2 Ejemplo Determinístico
  - 6.3 Ejemplo Estocástico
- 7 Funciones y rectas tangentes
  - 7.1 Definición de una función
  - 7.2 Graficar una función
  - 7.3 Estimando la pendiente de una recta tangente
- 8 Derivada de una Función
  - 8.1 Graficar una función y su derivada
  - 8.2 Encontrar la derivada (y la regla de la potencia)
  - 8.3 Encontrar y graficar derivadas parciales
- 9 Optimizacion mediante Derivadas - Funciones de una variable
  - 9.1 Igualando la derivada a cero
  - 9.2 Prueba de la segunda derivada
- 10 Optimizacion mediante Derivadas - Funciones de dos variables
  - 10.1 Encontrar todas las derivadas iguales a cero
  - 10.2 Prueba de la segunda derivada para dos Variables
- 11 Vectores Ortogonales e Independencia Lineal
  - 11.1 Prueba de ortogonalidad
  - 11.2 Ejemplo con regresión lineal
- 12 Eigenvectors y Eigenvalues
  - 12.1 Encontrar la matriz de covarianza y la descomposición eigen
  - 12.2 Comprensión de un Eigenvalue igual a cero
- 13 Descenso del Gradiente
  - 13.1 Ejecución del algoritmo de descenso de gradiente
  - 13.2 Visualización e interpretación de resultados
- 14 Descenso de gradiente en regresión lineal
  - 14.1 Generar datos y ajustar el modelo
  - 14.2 Ejecute el Descenso de gradiente
- 15 Referencia Bibliográfica



